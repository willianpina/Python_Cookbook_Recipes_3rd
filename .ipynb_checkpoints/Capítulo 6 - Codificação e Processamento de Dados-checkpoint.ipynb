{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center>Capítulo 6</h1>\n",
    "<h2 align=center>Codificação e Processamento de Dados</h2>\n",
    "<p align=center><img src=https://energiainteligenteufjf.com.br/wp-content/uploads/2021/02/curso-insofti-introducao-ao-processamento-de-dados-ipd.jpg width=500></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O foco principal deste capítulo é usar o Python para processar dados apresentados em diferentes tipos de codificações comuns, como arquivos CSV, JSON, XML e registros compactados em binários. Ao contrário do capítulo sobre estruturas de dados, este capítulo não se concentra em algoritmos específicos, mas no problema de obter e retirar dados de um programa.\n",
    "\n",
    "## 6.1. Lendo e gravando dados CSV\n",
    "\n",
    "**Problema**\n",
    "\n",
    "Você deseja ler ou gravar dados codificados como um arquivo CSV.\n",
    "\n",
    "**Solução**\n",
    "\n",
    "Para a maioria dos tipos de dados CSV, use a biblioteca `csv`. Por exemplo, suponha que você tenha alguns dados do mercado de ações em um arquivo chamado *stocks.csv* assim:\n",
    "~~~python\n",
    " Symbol,Price,Date,Time,Change,Volume\n",
    " \"AA\",39.48,\"6/11/2007\",\"9:36am\",-0.18,181800\n",
    " \"AIG\",71.38,\"6/11/2007\",\"9:36am\",-0.15,195500\n",
    " \"AXP\",62.58,\"6/11/2007\",\"9:36am\",-0.46,935000\n",
    " \"BA\",98.31,\"6/11/2007\",\"9:36am\",+0.12,104800\n",
    " \"C\",53.08,\"6/11/2007\",\"9:36am\",-0.25,360900\n",
    " \"CAT\",78.29,\"6/11/2007\",\"9:36am\",-0.23,225400\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['AA', '39.48', '6/11/2007', '9:36am', '-0.18', '181800']\n",
      "[]\n",
      "['AIG', '71.38', '6/11/2007', '9:36am', '-0.15', '195500']\n",
      "[]\n",
      "['AXP', '62.58', '6/11/2007', '9:36am', '-0.46', '935000']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No código anterior, *row* será uma tupla. Assim, para acessar determinados campos, você precisará usar indexação, como row[0] (Símbolo) e row[4] (Alterar).\n",
    "Como essa indexação geralmente pode ser confusa, este é um lugar onde você pode querer considerar o uso de tuplas nomeadas. Por exemplo:\n",
    "~~~python\n",
    "from collections import namedtuple\n",
    "with open('stock.csv') as f:\n",
    " f_csv = csv.reader(f)\n",
    " headings = next(f_csv)\n",
    " Row = namedtuple('Row', headings)\n",
    " for r in f_csv:\n",
    " row = Row(*r)\n",
    " # Process row\n",
    " ...\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso permitiria que você usasse os cabeçalhos das colunas, como `row.Symbol` e `row.Change`, em vez de índices. Deve-se notar que isso só funciona se os cabeçalhos das colunas forem identificadores Python válidos. Caso contrário, talvez seja necessário massagear os títulos iniciais (por exemplo, substituindo caracteres não identificadores por sublinhados ou similares).\n",
    "\n",
    "Outra alternativa é ler os dados como uma sequência de dicionários. Para isso, use este código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading as dicts\n",
      "     {'Symbol': 'AA', 'Price': '39.48', 'Date': '6/11/2007', 'Time': '9:36am', 'Change': '-0.18', 'Volume': '181800'}\n",
      "     {'Symbol': 'AIG', 'Price': '71.38', 'Date': '6/11/2007', 'Time': '9:36am', 'Change': '-0.15', 'Volume': '195500'}\n",
      "     {'Symbol': 'AXP', 'Price': '62.58', 'Date': '6/11/2007', 'Time': '9:36am', 'Change': '-0.46', 'Volume': '935000'}\n"
     ]
    }
   ],
   "source": [
    "print('Reading as dicts')\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.DictReader(f)\n",
    "    for row in f_csv:\n",
    "        # process row\n",
    "        print('    ', row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta versão, você acessaria os elementos de cada linha usando os cabeçalhos de linha. Por exemplo, row['Symbol'] ou row['Change']. \n",
    "\n",
    "Para gravar dados CSV, você também usa o módulo `csv`, mas cria um objeto de gravação. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Symbol','Price','Date','Time','Change','Volume']\n",
    "rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),\n",
    "        ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),\n",
    "        ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000),\n",
    "       ]\n",
    "with open('stocks.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você tiver os dados como uma sequência de dicionários, faça o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
    "rows = [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007','Time':'9:36am', 'Change':-0.18, 'Volume':181800},\n",
    "        {'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007','Time':'9:36am', 'Change':-0.15, 'Volume': 195500},\n",
    "        {'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007','Time':'9:36am', 'Change':-0.46, 'Volume': 935000},\n",
    "       ]\n",
    "\n",
    "with open('stocks.csv','w') as f:\n",
    "    f_csv = csv.DictWriter(f, headers)\n",
    "    f_csv.writeheader()\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussão**\n",
    "\n",
    "Você quase sempre deve preferir o uso do módulo `csv` em vez de tentar manualmente dividir e analisar os dados CSV. Por exemplo, você pode estar inclinado a apenas escrever algum código como este:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume\\n']\n",
      "['\\n']\n",
      "['AA', '39.48', '6/11/2007', '9:36am', '-0.18', '181800\\n']\n",
      "['\\n']\n",
      "['AIG', '71.38', '6/11/2007', '9:36am', '-0.15', '195500\\n']\n",
      "['\\n']\n",
      "['AXP', '62.58', '6/11/2007', '9:36am', '-0.46', '935000\\n']\n",
      "['\\n']\n"
     ]
    }
   ],
   "source": [
    "with open('stocks.csv') as f:\n",
    "    for line in f:\n",
    "        row = line.split(',')\n",
    "        print(row)\n",
    "        # process row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O problema com essa abordagem é que você ainda precisará lidar com alguns detalhes desagradáveis. Por exemplo, se algum dos campos estiver entre aspas, você terá que remover as aspas. Além disso, se um campo entre aspas contiver uma vírgula, o código será interrompido produzindo uma linha com o tamanho errado.\n",
    "\n",
    "Por padrão, a biblioteca `csv` é programada para entender as regras de codificação CSV usadas pelo Microsoft Excel. Esta é provavelmente a variante mais comum e provavelmente lhe dará a melhor compatibilidade. No entanto, se você consultar a documentação do `csv`, verá algumas maneiras de ajustar a codificação para diferentes formatos (por exemplo, alterando o caractere separador etc.). Por exemplo, se você quiser ler dados delimitados por tabulação, use isto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']\n",
      "['AA', '39.48', '6/11/2007', '9:36am', '-0.18', '181800']\n",
      "['AIG', '71.38', '6/11/2007', '9:36am', '-0.15', '195500']\n",
      "['AXP', '62.58', '6/11/2007', '9:36am', '-0.46', '935000']\n",
      "['BA', '98.31', '6/11/2007', '9:36am', '+0.12', '104800']\n",
      "['C', '53.08', '6/11/2007', '9:36am', '-0.25', '360900']\n",
      "['CAT', '78.29', '6/11/2007', '9:36am', '-0.23', '225400']\n"
     ]
    }
   ],
   "source": [
    "# Example of reading tab-separated values\n",
    "with open('stocks.tsv') as f:\n",
    "    f_tsv = csv.reader(f, delimiter='\\t')\n",
    "    for row in f_tsv:\n",
    "        # Process row\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você estiver lendo dados CSV e convertendo-os em tuplas nomeadas, precisará ter um pouco de cuidado ao validar os cabeçalhos das colunas. Por exemplo, um arquivo CSV pode ter uma linha de cabeçalho contendo caracteres identificadores inválidos como este:\n",
    "~~~python\n",
    "Street Address,Num-Premises,Latitude,Longitude\n",
    "5412 N CLARK,10,41.980262,-87.668452\n",
    "~~~\n",
    "\n",
    "Isso fará com que a criação de uma tupla nomeada falhe com uma exceção `ValueError`. Para contornar isso, talvez seja necessário esfregar os cabeçalhos primeiro. Por exemplo, carregando uma substituição regex em caracteres identificadores inválidos como este:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import namedtuple\n",
    "with open('stocks.tsv') as f:\n",
    "    f_csv = csv.reader(f, delimiter='\\t')\n",
    "    headers = [ re.sub('[^a-zA-Z_]', '_', h) for h in next(f_csv) ]\n",
    "    Row = namedtuple('Row', headers)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é importante enfatizar que o `csv` não tenta interpretar os dados ou convertê-los para um tipo diferente de uma *string*. Se essas conversões forem importantes, isso é algo que você precisará fazer sozinho. Aqui está um exemplo de como realizar conversões de tipo extra em dados CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800)\n",
      "()\n",
      "('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500)\n",
      "()\n",
      "('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "col_types = [str, float, str, str, float, int]\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        # Apply conversions to the row items\n",
    "        row = tuple(convert(value) for convert, value in zip(col_types, row))\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, aqui está um exemplo de conversão de campos selecionados de dicionários:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading as dicts with type conversion\n",
      "{'Symbol': 'AA', 'Price': 39.48, 'Date': '6/11/2007', 'Time': '9:36am', 'Change': -0.18, 'Volume': 181800}\n",
      "{'Symbol': 'AIG', 'Price': 71.38, 'Date': '6/11/2007', 'Time': '9:36am', 'Change': -0.15, 'Volume': 195500}\n",
      "{'Symbol': 'AXP', 'Price': 62.58, 'Date': '6/11/2007', 'Time': '9:36am', 'Change': -0.46, 'Volume': 935000}\n"
     ]
    }
   ],
   "source": [
    "print('Reading as dicts with type conversion')\n",
    "field_types = [ ('Price', float),('Change', float), ('Volume', int)]\n",
    "with open('stocks.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        row.update((key, conversion(row[key]))\n",
    "                   for key, conversion in field_types)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em geral, você provavelmente vai querer ter um pouco de cuidado com essas conversões. No mundo real, é comum que os arquivos CSV tenham valores ausentes, dados corrompidos e outros problemas que interromperiam as conversões de tipo. Portanto, a menos que seus dados sejam garantidos como livres de erros, isso é algo que você precisará considerar (talvez seja necessário adicionar tratamento de exceção adequado).\n",
    "\n",
    "Por fim, se seu objetivo ao ler dados CSV é realizar análises e estatísticas de dados, convém examinar o pacote Pandas. Pandas inclui uma função conveniente `pandas.read_csv()` que carregará dados CSV em um objeto DataFrame. A partir daí, você pode gerar várias estatísticas resumidas, filtrar os dados e realizar outros tipos de operações de alto nível. Um exemplo é dado na Receita 6.13.\n",
    "\n",
    "## 6.2. Lendo e gravando dados JSON\n",
    "\n",
    "**Problema**\n",
    "\n",
    "Você deseja ler ou gravar dados codificados como JSON (JavaScript Object Notation).\n",
    "\n",
    "**Solução**\n",
    "\n",
    "O módulo `json` fornece uma maneira fácil de codificar e decodificar dados em JSON. As duas funções principais são `json.dumps()` e `json.loads()`, espelhando a interface usada em outras bibliotecas de serialização, como `pickle`. Veja como você transforma uma estrutura de dados Python em JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = {\n",
    "    'name' : 'ACME',\n",
    "    'shares' : 100,\n",
    "    'price' : 542.23\n",
    "}\n",
    "\n",
    "json_str = json.dumps(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja como você transforma uma string codificada em JSON de volta em uma estrutura de dados Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estiver trabalhando com arquivos em vez de strings, você pode usar alternativamente `json.dump()` e `json.load()` para codificar e decodificar dados JSON. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing JSON data\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data back\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussão**\n",
    "\n",
    "A codificação JSON oferece suporte aos tipos básicos de **None**, **bool**, **int**, **float** e **str**, bem como listas, tuplas e dicionários que contêm esses tipos. Para dicionários, as chaves são consideradas strings (qualquer chave não string em um dicionário é convertida em strings durante a codificação).Para estar em conformidade com a especificação JSON, você deve codificar apenas listas e dicionários do Python. Além disso, em aplicativos da Web, é prática padrão que o objeto de nível superior seja um dicionário.\n",
    "\n",
    "O formato da codificação JSON é quase idêntico à sintaxe do Python, exceto por algumas pequenas alterações. Por exemplo, `True` é mapeado para **true**, `False` é mapeado para **false** e `None` é mapeado para **null**. Aqui está um exemplo que mostra como a codificação se parece:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"a\": true, \"b\": \"Hello\", \"c\": null}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a': True,\n",
    "     'b': 'Hello',\n",
    "     'c': None}\n",
    "json.dumps(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você estiver tentando examinar os dados que decodificou do JSON, muitas vezes pode ser difícil determinar sua estrutura simplesmente imprimindo-os, especialmente se os dados contiverem um nível profundo de estruturas aninhadas ou muitos campos. Para ajudar com isso, considere usar a função `pprint()` no módulo `pprint`. Isso alfabetizará as chaves e produzirá um dicionário de uma maneira mais sã. Aqui está um exemplo que ilustra como você imprimiria os resultados de uma pesquisa no Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boundingbox': ['-3.222', '-1.924', '-60.801', '-59.16'],\n",
      "  'category': 'boundary',\n",
      "  'display_name': 'Manaus, Região Geográfica Imediata de Manaus, Região '\n",
      "                  'Geográfica Intermediária de Manaus, Amazonas, Região Norte, '\n",
      "                  '69000-000, Brasil',\n",
      "  'icon': 'https://nominatim.openstreetmap.org/ui/mapicons/poi_boundary_administrative.p.20.png',\n",
      "  'importance': 0.6822901469283741,\n",
      "  'lat': '-3.1316333',\n",
      "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. '\n",
      "             'https://osm.org/copyright',\n",
      "  'lon': '-59.9825041',\n",
      "  'osm_id': 332493,\n",
      "  'osm_type': 'relation',\n",
      "  'place_id': 297367104,\n",
      "  'place_rank': 16,\n",
      "  'type': 'administrative'},\n",
      " {'boundingbox': ['-3.222', '-1.924', '-60.801', '-59.16'],\n",
      "  'category': 'boundary',\n",
      "  'display_name': 'Manaus, Região Geográfica Imediata de Manaus, Região '\n",
      "                  'Geográfica Intermediária de Manaus, Amazonas, Região Norte, '\n",
      "                  '69000-000, Brasil',\n",
      "  'icon': 'https://nominatim.openstreetmap.org/ui/mapicons/poi_boundary_administrative.p.20.png',\n",
      "  'importance': 0.41000000000000003,\n",
      "  'lat': '-2.573',\n",
      "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. '\n",
      "             'https://osm.org/copyright',\n",
      "  'lon': '-60.372468061674006',\n",
      "  'osm_id': 6255880,\n",
      "  'osm_type': 'relation',\n",
      "  'place_id': 298883723,\n",
      "  'place_rank': 18,\n",
      "  'type': 'administrative'},\n",
      " {'boundingbox': ['-1.5410701', '-1.5010701', '-46.0290779', '-45.9890779'],\n",
      "  'category': 'place',\n",
      "  'display_name': 'Manaus, Luís Domingues, Região Geográfica Imediata de '\n",
      "                  'Governador Nunes Freire, Região Geográfica Intermediária de '\n",
      "                  'Santa Inês-Bacabal, Maranhão, Região Nordeste, Brasil',\n",
      "  'icon': 'https://nominatim.openstreetmap.org/ui/mapicons/poi_place_village.p.20.png',\n",
      "  'importance': 0.385,\n",
      "  'lat': '-1.5210701',\n",
      "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. '\n",
      "             'https://osm.org/copyright',\n",
      "  'lon': '-46.0090779',\n",
      "  'osm_id': 4647841617,\n",
      "  'osm_type': 'node',\n",
      "  'place_id': 53172257,\n",
      "  'place_rank': 19,\n",
      "  'type': 'village'},\n",
      " {'boundingbox': ['-11.1329897', '-11.0929897', '-68.6230167', '-68.5830167'],\n",
      "  'category': 'place',\n",
      "  'display_name': 'Manaus, Epitaciolândia, Região Geográfica Imediata de '\n",
      "                  'Brasiléia, Região Geográfica Intermediária de Rio Branco, '\n",
      "                  'Acre, Região Norte, Brasil',\n",
      "  'icon': 'https://nominatim.openstreetmap.org/ui/mapicons/poi_place_village.p.20.png',\n",
      "  'importance': 0.36,\n",
      "  'lat': '-11.1129897',\n",
      "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. '\n",
      "             'https://osm.org/copyright',\n",
      "  'lon': '-68.6030167',\n",
      "  'osm_id': 3809552513,\n",
      "  'osm_type': 'node',\n",
      "  'place_id': 45564349,\n",
      "  'place_rank': 20,\n",
      "  'type': 'hamlet'},\n",
      " {'boundingbox': ['-9.373781', '-9.333781', '-69.934744', '-69.894744'],\n",
      "  'category': 'place',\n",
      "  'display_name': 'Manaus, Manoel Urbano, Região Geográfica Imediata de Sena '\n",
      "                  'Madureira, Região Geográfica Intermediária de Rio Branco, '\n",
      "                  'Acre, Região Norte, Brasil',\n",
      "  'icon': 'https://nominatim.openstreetmap.org/ui/mapicons/poi_place_village.p.20.png',\n",
      "  'importance': 0.36,\n",
      "  'lat': '-9.353781',\n",
      "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. '\n",
      "             'https://osm.org/copyright',\n",
      "  'lon': '-69.914744',\n",
      "  'osm_id': 416760249,\n",
      "  'osm_type': 'node',\n",
      "  'place_id': 3139193,\n",
      "  'place_rank': 20,\n",
      "  'type': 'hamlet'},\n",
      " {'boundingbox': ['54.8125528', '54.8450191', '52.9462608', '53.0729952'],\n",
      "  'category': 'waterway',\n",
      "  'display_name': 'Маняус, Агерзе, Агерзинское сельское поселение, '\n",
      "                  'Азнакаевский район, Татарстан, Приволжский федеральный '\n",
      "                  'округ, 423332, Россия',\n",
      "  'importance': 0.282582546755277,\n",
      "  'lat': '54.8288816',\n",
      "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. '\n",
      "             'https://osm.org/copyright',\n",
      "  'lon': '53.0160573',\n",
      "  'osm_id': 192219914,\n",
      "  'osm_type': 'way',\n",
      "  'place_id': 150443725,\n",
      "  'place_rank': 19,\n",
      "  'type': 'river'},\n",
      " {'boundingbox': ['25.2035461', '25.2060466', '55.1627647', '55.1659216'],\n",
      "  'category': 'place',\n",
      "  'display_name': 'ماناوس, دبي, الإمارات العربية المتحدة',\n",
      "  'importance': 0.25,\n",
      "  'lat': '25.204849199999998',\n",
      "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. '\n",
      "             'https://osm.org/copyright',\n",
      "  'lon': '55.16389272585206',\n",
      "  'osm_id': 9641826,\n",
      "  'osm_type': 'relation',\n",
      "  'place_id': 299102404,\n",
      "  'place_rank': 20,\n",
      "  'type': 'islet'},\n",
      " {'boundingbox': ['-33.8157766', '-33.8155161', '-70.7416601', '-70.7403156'],\n",
      "  'category': 'highway',\n",
      "  'display_name': 'Manaus, Colonia San Pablo, Paine, Provincia de Maipo, '\n",
      "                  'Región Metropolitana de Santiago, Chile',\n",
      "  'importance': 0.21,\n",
      "  'lat': '-33.8156207',\n",
      "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. '\n",
      "             'https://osm.org/copyright',\n",
      "  'lon': '-70.7411199',\n",
      "  'osm_id': 85509942,\n",
      "  'osm_type': 'way',\n",
      "  'place_id': 124473038,\n",
      "  'place_rank': 26,\n",
      "  'type': 'residential'},\n",
      " {'boundingbox': ['-3.0418864', '-3.0417864', '-60.0521299', '-60.0520299'],\n",
      "  'category': 'man_made',\n",
      "  'display_name': 'Manaus, Rua Maracanã, Redenção, Manaus, Região Geográfica '\n",
      "                  'Imediata de Manaus, Região Geográfica Intermediária de '\n",
      "                  'Manaus, Amazonas, Região Norte, 69000-000, Brasil',\n",
      "  'importance': 0.11010000000000002,\n",
      "  'lat': '-3.0418364',\n",
      "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. '\n",
      "             'https://osm.org/copyright',\n",
      "  'lon': '-60.0520799',\n",
      "  'osm_id': 4792611159,\n",
      "  'osm_type': 'node',\n",
      "  'place_id': 55421930,\n",
      "  'place_rank': 30,\n",
      "  'type': 'tower'},\n",
      " {'boundingbox': ['4.704509', '4.704609', '-74.124304', '-74.124204'],\n",
      "  'category': 'amenity',\n",
      "  'display_name': 'Manaus, Calle 70, UPZs Localidad Engativá, Localidad '\n",
      "                  'Engativá, Bogotá, Bogotá, Distrito Capital, 111041, '\n",
      "                  'Colombia',\n",
      "  'icon': 'https://nominatim.openstreetmap.org/ui/mapicons/food_restaurant.p.20.png',\n",
      "  'importance': 0.11010000000000002,\n",
      "  'lat': '4.704559',\n",
      "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. '\n",
      "             'https://osm.org/copyright',\n",
      "  'lon': '-74.124254',\n",
      "  'osm_id': 5186319381,\n",
      "  'osm_type': 'node',\n",
      "  'place_id': 57801650,\n",
      "  'place_rank': 30,\n",
      "  'type': 'restaurant'}]\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "u = urlopen('https://nominatim.openstreetmap.org/search.php?q=Manaus&format=jsonv2')\n",
    "resp = json.loads(u.read().decode('utf-8'))\n",
    "from pprint import pprint\n",
    "pprint(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente, a decodificação JSON criará dicts ou listas a partir dos dados fornecidos. Se você deseja criar diferentes tipos de objetos, forneça o *object_pairs_hook* ou *object_hook* para `json.loads()`. Por exemplo, aqui está como você decodificaria dados JSON, preservando sua ordem em um `OrderedDict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n",
    "from collections import OrderedDict\n",
    "data = json.loads(s, object_pairs_hook=OrderedDict)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui está como você pode transformar um dicionário JSON em um objeto Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONObject:\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(s, object_hook=JSONObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACME'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data.shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490.1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste último exemplo, o dicionário criado pela decodificação dos dados JSON é passado como um único argumento para `__init__()`. A partir daí, você está livre para usá-lo como quiser, como usá-lo diretamente como o dicionário de instância do objeto.\n",
    "Existem algumas opções que podem ser úteis para codificar JSON. Se você quiser que a saída seja bem formatada, você pode usar o argumento `indent` para `json.dumps()`. Isso faz com que a saída seja bem impressa em um formato semelhante ao da função `pprint()`. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"ACME\", \"shares\": 100, \"price\": 542.23}\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'name' : 'ACME',\n",
    "    'shares' : 100,\n",
    "    'price' : 542.23\n",
    "}\n",
    "\n",
    "print(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"ACME\",\n",
      "    \"shares\": 100,\n",
      "    \"price\": 542.23\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você quiser que as chaves sejam classificadas na saída, use o argumento `sort_keys`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"ACME\", \"price\": 542.23, \"shares\": 100}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As instâncias normalmente não são serializáveis como JSON. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "p = Point(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~python\n",
    "json.dumps(p)\n",
    "Traceback (most recent call last):\n",
    " File \"<stdin>\", line 1, in <module>\n",
    " File \"/usr/local/lib/python3.3/json/__init__.py\", line 226, in dumps\n",
    " return _default_encoder.encode(obj)\n",
    " File \"/usr/local/lib/python3.3/json/encoder.py\", line 187, in encode\n",
    " chunks = self.iterencode(o, _one_shot=True)\n",
    " File \"/usr/local/lib/python3.3/json/encoder.py\", line 245, in iterencode\n",
    " return _iterencode(o, 0)\n",
    " File \"/usr/local/lib/python3.3/json/encoder.py\", line 169, in default\n",
    " raise TypeError(repr(o) + \" is not JSON serializable\")\n",
    "TypeError: <__main__.Point object at 0x1006f2650> is not JSON serializable\n",
    ">>>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você deseja serializar instâncias, pode fornecer uma função que recebe uma instância como entrada e retorna um dicionário que pode ser serializado. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_instance(obj):\n",
    "    d = { '__classname__' : type(obj).__name__ }\n",
    "    d.update(vars(obj))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você quiser obter uma instância de volta, você pode escrever um código como este:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping names to known classes\n",
    "classes = {\n",
    "    'Point' : Point\n",
    "}\n",
    "\n",
    "def unserialize_object(d):\n",
    "    clsname = d.pop('__classname__', None)\n",
    "    if clsname:\n",
    "        cls = classes[clsname]\n",
    "        obj = cls.__new__(cls) # Make instance without calling __init__\n",
    "        for key, value in d.items():\n",
    "            setattr(obj, key, value)\n",
    "            return obj\n",
    "    else:\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui está um exemplo de como essas funções são usadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"__classname__\": \"Point\", \"x\": 2, \"y\": 3}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Point(2,3)\n",
    "s = json.dumps(p, default=serialize_instance)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Point at 0x1c96a3cfd90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = json.loads(s, object_hook=unserialize_object)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O módulo json tem uma variedade de outras opções para controlar a interpretação de números de baixo nível, valores especiais como NaN e muito mais. Consulte a documentação para mais detalhes.\n",
    "\n",
    "## 6.3. Analisando dados XML simples\n",
    "\n",
    "**Problema**\n",
    "\n",
    "Você gostaria de extrair dados de um documento XML simples.\n",
    "\n",
    "**Solução**\n",
    "O módulo `xml.etree.ElementTree` pode ser usado para extrair dados de documentos XML simples. Para ilustrar, suponha que você queira analisar e fazer um resumo do feed RSS no Planet Python. Aqui está um script que fará isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse\n",
    "# Download the RSS feed and parse it\n",
    "u = urlopen('http://planet.python.org/rss20.xml')\n",
    "doc = parse(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Python: Refactoring: Prepare Your Code to Get Help\n",
      "Tue, 08 Nov 2022 14:00:00 +0000\n",
      "https://realpython.com/courses/refactoring-code-to-get-help/\n",
      "\n",
      "PyCharm: Support Python with JetBrains and PyCharm\n",
      "Tue, 08 Nov 2022 13:02:00 +0000\n",
      "https://blog.jetbrains.com/pycharm/2022/11/support-python-with-jetbrains-and-pycharm/\n",
      "\n",
      "James Bennett: A Python 3.11 \"gotcha\"\n",
      "Tue, 08 Nov 2022 01:12:40 +0000\n",
      "https://www.b-list.org/weblog/2022/nov/08/python-311-gotcha/\n",
      "\n",
      "Matthew Wright: Matching data between data sources with Python\n",
      "Mon, 07 Nov 2022 17:55:52 +0000\n",
      "https://www.wrighters.io/matching-data-between-data-sources-with-python/\n",
      "\n",
      "PyBites: New on our platform: Typer learning path\n",
      "Mon, 07 Nov 2022 17:06:33 +0000\n",
      "https://pybit.es/articles/new-on-our-platform-typer-learning-path/\n",
      "\n",
      "PyCharm: Webinar: “Speech-to-image generation using Jina”\n",
      "Mon, 07 Nov 2022 15:13:00 +0000\n",
      "https://blog.jetbrains.com/pycharm/2022/11/webinar-speech-to-image-generation-using-jina/\n",
      "\n",
      "Real Python: Python News: What's New From October 2022\n",
      "Mon, 07 Nov 2022 14:00:00 +0000\n",
      "https://realpython.com/python-news-october-2022/\n",
      "\n",
      "Python for Beginners: Send Email Using Python\n",
      "Mon, 07 Nov 2022 14:00:00 +0000\n",
      "https://www.pythonforbeginners.com/api/send-email-using-python\n",
      "\n",
      "Mike Driscoll: PyDev of the Week: Kirk Byers\n",
      "Mon, 07 Nov 2022 13:33:40 +0000\n",
      "https://www.blog.pythonlibrary.org/2022/11/07/pydev-of-the-week-kirk-byers/\n",
      "\n",
      "Luke Plant: Better Python code grepping with pyastgrep\n",
      "Mon, 07 Nov 2022 08:37:46 +0000\n",
      "https://lukeplant.me.uk/blog/posts/grep-python-syntax-using-ast-pyastgrep/\n",
      "\n",
      "Mike C. Fletcher: Finally Got Potions (ItemMeta) and Signs (BlockState) working\n",
      "Mon, 07 Nov 2022 03:29:36 +0000\n",
      "http://blog.vrplumber.com/b/2022/11/06/finally-got-potions-itemmeta-and-signs-blockstate-working/\n",
      "\n",
      "Podcast.__init__: Skip Straight To The Fun Part Of Your Project With PyScaffold\n",
      "Mon, 07 Nov 2022 00:20:26 +0000\n",
      "https://www.pythonpodcast.com/pyscaffold-project-template-boilerplate-episode-384/\n",
      "\n",
      "Read the Docs: Read the Docs newsletter - November 2022\n",
      "Mon, 07 Nov 2022 00:00:00 +0000\n",
      "https://blog.readthedocs.com/newsletter-november-2022/\n",
      "\n",
      "The Python Coding Blog: Moving On From The Basics of Python Functions [#1 in Intermediate Python Functions Series]\n",
      "Sat, 05 Nov 2022 21:04:00 +0000\n",
      "https://thepythoncodingbook.com/2022/11/05/intermediate-python-functions-series-1/\n",
      "\n",
      "PyPy: PyPy and conda-forge\n",
      "Sat, 05 Nov 2022 17:00:25 +0000\n",
      "https://www.pypy.org/posts/2022/11/pypy-and-conda-forge.html\n",
      "\n",
      "Mike C. Fletcher: Creating some Pycraft Videos\n",
      "Sat, 05 Nov 2022 03:44:55 +0000\n",
      "http://blog.vrplumber.com/b/2022/11/04/creating-some-pycraft-videos/\n",
      "\n",
      "PyCharm: PyCharm 2022.3 EAP 4 is out!\n",
      "Fri, 04 Nov 2022 14:02:32 +0000\n",
      "https://blog.jetbrains.com/pycharm/2022/11/2022-3-eap-4-2/\n",
      "\n",
      "Python for Beginners: Concatenate, Merge, and Join Pandas DataFrames\n",
      "Fri, 04 Nov 2022 13:00:00 +0000\n",
      "https://www.pythonforbeginners.com/basics/concatenate-merge-and-join-pandas-dataframes\n",
      "\n",
      "Real Python: The Real Python Podcast – Episode #131: Exploring the New Features of Python 3.11\n",
      "Fri, 04 Nov 2022 12:00:00 +0000\n",
      "https://realpython.com/podcasts/rpp/131/\n",
      "\n",
      "EuroPython: EuroPython 2022: Videos &amp; Thanks!\n",
      "Fri, 04 Nov 2022 11:30:00 +0000\n",
      "https://blog.europython.eu/europython-2022-our-videos-are-now-up-on-the-mystical-internet/\n",
      "\n",
      "Python Engineering at Microsoft: Python in Visual Studio Code – November 2022 Release\n",
      "Thu, 03 Nov 2022 16:33:40 +0000\n",
      "https://devblogs.microsoft.com/python/python-in-visual-studio-code-november-2022-release/\n",
      "\n",
      "Mike Driscoll: Python 101 - How to Work with CSV files\n",
      "Thu, 03 Nov 2022 12:45:09 +0000\n",
      "https://www.blog.pythonlibrary.org/2022/11/03/python-101-how-to-work-with-csv-files/\n",
      "\n",
      "PyBites: Focus on what you can control\n",
      "Thu, 03 Nov 2022 07:22:45 +0000\n",
      "https://pybit.es/articles/pp94-focus-on-what-you-can-control/\n",
      "\n",
      "Brett Cannon: Unravelling assignment expressions\n",
      "Wed, 02 Nov 2022 19:23:55 +0000\n",
      "https://snarky.ca/unravelling-assignment-expressions/\n",
      "\n",
      "Real Python: Should You Update to the Latest Python Bugfix Version?\n",
      "Wed, 02 Nov 2022 14:00:00 +0000\n",
      "https://realpython.com/python-bugfix-version/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract and output tags of interest\n",
    "for item in doc.iterfind('channel/item'):\n",
    "    title = item.findtext('title')\n",
    "    date = item.findtext('pubDate')\n",
    "    link = item.findtext('link')\n",
    "    print(title)\n",
    "    print(date)\n",
    "    print(link)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviamente, se você quiser fazer mais processamento, precisará substituir as instruções `print()` por algo mais interessante.\n",
    "\n",
    "**Discussão**\n",
    "\n",
    "Trabalhar com dados codificados como XML é comum em muitos aplicativos. O XML não é apenas amplamente usado como formato para troca de dados na Internet, mas também é um formato comum para armazenar dados de aplicativos (por exemplo, processamento de texto, bibliotecas de música etc.). A discussão a seguir já pressupõe que o leitor esteja familiarizado com os fundamentos do XML.\n",
    "\n",
    "Em muitos casos, quando o XML está simplesmente sendo usado para armazenar dados, a estrutura do documento é compacta e direta. Por exemplo, o feed RSS do exemplo é semelhante ao seguinte:\n",
    "\n",
    "~~~html\n",
    "<?xml version=\"1.0\"?>\n",
    " <rss version=\"2.0\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\">\n",
    " <channel>\n",
    "     <title>Planet Python</title>\n",
    "     <link>http://planet.python.org/</link>\n",
    "     <language>en</language>\n",
    "     <description>Planet Python - http://planet.python.org/</description>\n",
    "     <item>\n",
    "         <title>Steve Holden: Python for Data Analysis</title>\n",
    "         <guid>http://holdenweb.blogspot.com/...-data-analysis.html</guid>\n",
    "         <link>http://holdenweb.blogspot.com/...-data-analysis.html</link>\n",
    "     <description>...</description>\n",
    "     <pubDate>Mon, 19 Nov 2012 02:13:51 +0000</pubDate>\n",
    "     </item>\n",
    "<item>\n",
    "    <title>Vasudev Ram: The Python Data model (for v2 and v3)</title>\n",
    "    <guid>http://jugad2.blogspot.com/...-data-model.html</guid>\n",
    "    <link>http://jugad2.blogspot.com/...-data-model.html</link>\n",
    "<description>...</description>\n",
    "<pubDate>Sun, 18 Nov 2012 22:06:47 +0000</pubDate>\n",
    "</item>\n",
    "<item>\n",
    "    <title>Python Diary: Been playing around with Object Databases</title>\n",
    "    <guid>http://www.pythondiary.com/...-object-databases.html</guid>\n",
    "    <link>http://www.pythondiary.com/...-object-databases.html</link>\n",
    "<description>...</description>\n",
    "<pubDate>Sun, 18 Nov 2012 20:40:29 +0000</pubDate>\n",
    "</item>\n",
    "...\n",
    " </channel>\n",
    "</rss>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `xml.etree.ElementTree.parse()` analisa todo o documento XML em um objeto de documento. A partir daí, você usa métodos como `find()`, `iterfind()` e `findtext()` para pesquisar elementos XML específicos. Os argumentos para essas funções são os nomes de uma tag específica, como canal/item ou título.\n",
    "\n",
    "Ao especificar tags, você precisa levar em consideração a estrutura geral do documento. Cada operação de localização ocorre em relação a um elemento inicial. Da mesma forma, o tagname que você fornece para cada operação também é relativo ao início. No exemplo, a chamada para `doc.iterfind('canal/item')` procura todos os elementos “item” sob um elemento “canal”. doc representa a parte superior do documento (o elemento “rss” de nível superior). As últimas chamadas para `item.findtext()` ocorrem em relação aos elementos “item” encontrados.\n",
    "\n",
    "Cada elemento representado pelo módulo `ElementTree` tem alguns atributos e métodos essenciais que são úteis ao analisar. O atributo tag contém o nome da tag, o atributo text contém texto incluído e o método `get()` pode ser usado para extrair atributos (se houver). Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.etree.ElementTree.ElementTree at 0x1c96a3df970>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'title' at 0x000001C96C2DECC0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = doc.find('channel/title')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Planet Python'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get('some_attribute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deve-se notar que `xml.etree.ElementTree` não é a única opção para análise XML. Para aplicativos mais avançados, você pode considerar `lxml`. Ele usa a mesma interface de programação do `ElementTree`, então o exemplo mostrado nesta receita funciona da mesma maneira. Você simplesmente precisa alterar a primeira importação `from lxml.etree import parse.lxml` oferece o benefício de ser totalmente compatível com os padrões XML. Também é extremamente **rápido** e oferece suporte para recursos como validação, XSLT e XPath.\n",
    "\n",
    "## 6.4. Analisando arquivos XML enormes de forma incremental\n",
    "\n",
    "**Problema**\n",
    "\n",
    "Você precisa extrair dados de um documento XML enorme usando o mínimo de memória possível.\n",
    "\n",
    "**Solução**\n",
    "\n",
    "Sempre que você se deparar com o problema do processamento incremental de dados, você deve pensar em iteradores e geradores. Aqui está uma função simples que pode ser usada para processar de forma incremental arquivos XML enormes usando uma pegada de memória muito pequena:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import iterparse\n",
    "def parse_and_remove(filename, path):\n",
    "    path_parts = path.split('/')\n",
    "    doc = iterparse(filename, ('start', 'end'))\n",
    "    # Skip the root element\n",
    "    next(doc)\n",
    "    tag_stack = []\n",
    "    elem_stack = []\n",
    "    for event, elem in doc:\n",
    "        if event == 'start':\n",
    "            tag_stack.append(elem.tag)\n",
    "            elem_stack.append(elem)\n",
    "        elif event == 'end':\n",
    "            if tag_stack == path_parts:\n",
    "                yield elem\n",
    "                elem_stack[-2].remove(elem)\n",
    "            try:\n",
    "                tag_stack.pop()\n",
    "                elem_stack.pop()\n",
    "            except IndexError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar a função, agora você precisa encontrar um arquivo XML grande para trabalhar. Muitas vezes você pode encontrar esses arquivos em sites governamentais e de dados abertos. Por exemplo, você pode baixar o banco de dados de buracos de Chicago como XML. No momento da redação deste artigo, o arquivo baixado consiste em mais de 100.000 linhas de dados, que são codificados assim:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<response>\n",
    "<row>\n",
    "<row ...>\n",
    "<creation_date>2012-11-18T00:00:00</creation_date>\n",
    "        <status>Completed</status>\n",
    "        <completion_date>2012-11-18T00:00:00</completion_date>\n",
    "                <service_request_number>12-01906549</service_request_number>\n",
    "                <type_of_service_request>Pot Hole in Street</type_of_service_request>\n",
    "                <current_activity>Final Outcome</current_activity>\n",
    "                <most_recent_action>CDOT Street Cut ... Outcome</most_recent_action>\n",
    "                <street_address>4714 S TALMAN AVE</street_address>\n",
    "                <zip>60632</zip>\n",
    "                <x_coordinate>1159494.68618856</x_coordinate>\n",
    "                <y_coordinate>1873313.83503384</y_coordinate>\n",
    "                <ward>14</ward>\n",
    "                <police_district>9</police_district>\n",
    "                <community_area>58</community_area>\n",
    "                <latitude>41.808090232127896</latitude>\n",
    "                <longitude>-87.69053684711305</longitude>\n",
    "                <location latitude=\"41.808090232127896\"\n",
    "                longitude=\"-87.69053684711305\" />\n",
    "                </row>\n",
    "                <row ...>\n",
    "                <creation_date>2012-11-18T00:00:00</creation_date>\n",
    "                        <status>Completed</status>\n",
    "                        <completion_date>2012-11-18T00:00:00</completion_date>\n",
    "                                <service_request_number>12-01906695</service_request_number>\n",
    "                                <type_of_service_request>Pot Hole in Street</type_of_service_request>\n",
    "                                <current_activity>Final Outcome</current_activity>\n",
    "                                <most_recent_action>CDOT Street Cut ... Outcome</most_recent_action>\n",
    "                                <street_address>3510 W NORTH AVE</street_address>\n",
    "                                <zip>60647</zip>\n",
    "                                <x_coordinate>1152732.14127696</x_coordinate>\n",
    "                                <y_coordinate>1910409.38979075</y_coordinate>\n",
    "                                <ward>26</ward>\n",
    "                                <police_district>14</police_district>\n",
    "                                <community_area>23</community_area>\n",
    "                                <latitude>41.91002084292946</latitude>\n",
    "                                <longitude>-87.71435952353961</longitude>\n",
    "                                <location latitude=\"41.91002084292946\" longitude=\"-87.71435952353961\" />\n",
    "                                </row>\n",
    "                                </row>\n",
    "                                </response>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponha que você queira escrever um script que classifique os CEPs pelo número de relatórios de buracos. Para fazer isso, você poderia escrever um código como este:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60629 22554\n",
      "60617 19126\n",
      "60628 19034\n",
      "60618 18630\n",
      "60634 18244\n",
      "60647 17758\n",
      "60620 17743\n",
      "60643 17486\n",
      "60619 16867\n",
      "60632 16753\n",
      "60638 16351\n",
      "60639 15810\n",
      "60630 15380\n",
      "60608 15049\n",
      "60609 13858\n",
      "60641 13526\n",
      "60623 12973\n",
      "60625 12678\n",
      "60614 12527\n",
      "60631 12406\n",
      "60646 10908\n",
      "60652 10172\n",
      "60651 10000\n",
      "60645 9804\n",
      "60622 9572\n",
      "60644 9381\n",
      "60649 9260\n",
      "60659 8975\n",
      "60612 8871\n",
      "60636 8806\n",
      "60657 8782\n",
      "60626 8666\n",
      "60637 8619\n",
      "60616 7845\n",
      "60660 7819\n",
      "60655 7651\n",
      "60640 7516\n",
      "60624 7063\n",
      "60656 6834\n",
      "60607 6579\n",
      "60621 6185\n",
      "60642 6142\n",
      "60615 5322\n",
      "60613 5100\n",
      "60611 4942\n",
      "60610 4616\n",
      "60707 4460\n",
      "60653 4174\n",
      "60605 3215\n",
      "60601 3061\n",
      "60654 2981\n",
      "60633 2932\n",
      "None 2318\n",
      "60661 1420\n",
      "60603 1177\n",
      "60604 1022\n",
      "60606 1008\n",
      "60827 988\n",
      "0 719\n",
      "60602 706\n",
      "60666 73\n",
      "60635 27\n",
      "60627 11\n",
      "60687 2\n",
      "60018 1\n"
     ]
    }
   ],
   "source": [
    "from xml.etree.ElementTree import parse\n",
    "from collections import Counter\n",
    "potholes_by_zip = Counter()\n",
    "doc = parse('potholes1.xml')\n",
    "for pothole in doc.iterfind('row/row'):\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta versão do código é executada com uma pegada de memória de apenas 7 MB—uma enorme economia!\n",
    "\n",
    "**Discussão**\n",
    "\n",
    "Esta receita se baseia em dois recursos principais do módulo ElementTree. Primeiro, o método iterparse() permite o processamento incremental de documentos XML. Para usá-lo, você fornece o nome do arquivo junto com uma lista de eventos que consiste em um ou mais dos seguintes:**start**, **end**, **start-ns** e **end-ns**. O iterador criado por `iterparse()` produz tuplas no form(event, elem), onde event é um dos eventos listados e elem é o elemento XML resultante. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iterparse('potholes.xml',('start','end'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start', <Element 'response' at 0x000001C96C643E50>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start', <Element 'row' at 0x000001C96D091040>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start', <Element 'row' at 0x000001C96D0763B0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start', <Element 'creation_date' at 0x000001C96D0760E0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('end', <Element 'creation_date' at 0x000001C96D0760E0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start', <Element 'status' at 0x000001C96D076220>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('end', <Element 'status' at 0x000001C96D076220>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os eventos **start** são criados quando um elemento é criado pela primeira vez, mas ainda não é preenchido com nenhum outro dado (por exemplo, elementos filho). eventos **end** são criados quando um elemento é concluído.\n",
    "\n",
    "Embora não sejam mostrados nesta receita, os eventos **start-ns** e **end-ns** são usados para manipular declarações de namespace XML.\n",
    "\n",
    "Nesta receita, os eventos de **start** e **end** são usados para gerenciar pilhas de elementos e tags. As pilhas representam a estrutura hierárquica atual do documento conforme ele está sendo analisado e também são usadas para determinar se um elemento corresponde ao caminho solicitado fornecido à função **parse_and_remove()** . Se uma correspondência for feita, o rendimento é usado para emiti-lo de volta para o chamador.\n",
    "\n",
    "A seguinte declaração após o **yield** é o recurso principal do **ElementTree** que faz com que essa receita economize memória:\n",
    "~~~python\n",
    "elem_stack[-2].remove(elem)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa instrução faz com que o elemento gerado anteriormente seja removido de seu pai.Supondo que nenhuma referência seja deixada a ele em nenhum outro lugar, o elemento é destruído e a memória recuperada.\n",
    "\n",
    "O efeito **end** da análise iterativa e a remoção de nós é uma varredura incremental altamente eficiente sobre o documento. Em nenhum momento uma árvore de documentos completa é construída. No entanto, ainda é possível escrever código que processe os dados XML de maneira direta.\n",
    "\n",
    "A principal desvantagem dessa receita é seu desempenho em tempo de execução. Quando testada, a versão do código que lê o documento inteiro na memória primeiro é executada aproximadamente duas vezes mais rápido que a versão que o processa de forma incremental. No entanto, requer mais de 60 vezes mais memória. Portanto, se o uso de memória é uma preocupação maior, a versão incremental é uma grande vitória."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
